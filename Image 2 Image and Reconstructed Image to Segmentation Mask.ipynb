{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ms_ssim\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tensorboardX import SummaryWriter \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "MODEL_NAME = \"IMAGE2IMAGE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Auto Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOENCODER\n",
      "Latent's Shape: torch.Size([1, 512, 4, 4])\n",
      "Output's ShapeL torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, blk, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.blk = blk\n",
    "        self.conv1_a = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv1_b = nn.Conv2d(3, in_channels, 3, 1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2)) \n",
    "\n",
    "    def forward(self, x, scale_img=\"none\"):\n",
    "        if ((self.blk==\"first\") or (self.blk==\"bottleneck\")):\n",
    "            x1 = self.relu(self.conv1_a(x))\n",
    "            x1 = self.relu(self.conv2(x1))\n",
    "        else:\n",
    "            skip_x = self.relu(self.conv1_b(scale_img))\n",
    "            x1 = torch.cat([skip_x, x], dim=1)\n",
    "            x1 = self.relu(self.conv2(x1))\n",
    "            x1 = self.relu(self.conv3(x1))\n",
    "        out = self.maxpool(self.dropout(x1))\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor = 2)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.upsample(x)\n",
    "        x1 = self.relu(self.conv1(x1))\n",
    "        x1 = self.relu(self.conv2(x1))\n",
    "        x1 = self.relu(self.conv3(x1))\n",
    "        out = self.dropout(x1)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DeepSupervisionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor = 2)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, 1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 3, 1, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.upsample(x)\n",
    "        x1 = self.relu(self.conv1(x1))\n",
    "        x1 = self.relu(self.conv2(x1))\n",
    "        out = self.sigmoid(self.conv3(x1))\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        filters = [8, 16, 32, 64, 128, 512] \n",
    "        self.drp_out = 0.3\n",
    "        self.scale_img = nn.AvgPool2d(2, 2)   \n",
    "\n",
    "        self.block_1 = EncoderBlock(\"first\", 3, filters[0])\n",
    "        self.block_2 = EncoderBlock(\"second\", filters[0], filters[1])\n",
    "        self.block_3 = EncoderBlock(\"third\", filters[1], filters[2])\n",
    "        self.block_4 = EncoderBlock(\"fourth\", filters[2], filters[3])\n",
    "        self.block_5 = EncoderBlock(\"fifth\", filters[3], filters[4])\n",
    "        self.block_6 = EncoderBlock(\"bottleneck\", filters[4], filters[5])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multi-scale input\n",
    "        scale_img_2 = self.scale_img(x)\n",
    "        scale_img_3 = self.scale_img(scale_img_2)\n",
    "        scale_img_4 = self.scale_img(scale_img_3)  \n",
    "        scale_img_5 = self.scale_img(scale_img_4)\n",
    "\n",
    "        x1 = self.block_1(x)\n",
    "        x2 = self.block_2(x1, scale_img_2)\n",
    "        x3 = self.block_3(x2, scale_img_3)\n",
    "        x4 = self.block_4(x3, scale_img_4)\n",
    "        x5 = self.block_5(x4, scale_img_5)\n",
    "        x6 = self.block_6(x5)\n",
    "        return x6\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        filters = [512, 128, 64, 32, 16, 8]\n",
    "        self.drp_out = 0.3\n",
    "\n",
    "        self.block_5 = DecoderBlock(filters[0], filters[1])\n",
    "        self.block_4 = DecoderBlock(filters[1], filters[2])\n",
    "        self.block_3 = DecoderBlock(filters[2], filters[3])\n",
    "        self.block_2 = DecoderBlock(filters[3], filters[4])\n",
    "        self.block_1 = DecoderBlock(filters[4], filters[5])\n",
    "        self.ds = DeepSupervisionBlock(filters[5], 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block_5(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_1(x)\n",
    "        out9 = self.ds(x)\n",
    "        return out9\n",
    "\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        output = self.decoder(latent)\n",
    "        return latent, output\n",
    "\n",
    "\n",
    "\n",
    "print(\"AUTOENCODER\")\n",
    "data = (torch.rand(size=(1, 3, 256, 256)))\n",
    "AE = AutoEncoder()\n",
    "img_out = AE(data)\n",
    "print(\"Latent's Shape:\", img_out[0].shape)\n",
    "print(\"Output's ShapeL\", img_out[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNET\n",
      "Output's Shape torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "        self.conv = nn.Conv2d(in_channels=features, out_channels=out_channels, kernel_size=1)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        # return self.softmax(self.conv(dec1))\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    \n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (name + \"conv1\",nn.Conv2d( in_channels=in_channels, out_channels=features, kernel_size=3, padding=1, bias=False)),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    ( name + \"conv2\", nn.Conv2d( in_channels=features, out_channels=features, kernel_size=3, padding=1, bias=False, )),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"\\nUNET\")\n",
    "data = img_out[1]\n",
    "unet = UNet()\n",
    "seg_out = unet(data)\n",
    "print(\"Output's Shape\", seg_out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Image2Image and Reconstructed Image to Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model\n",
      "Latent's Shape:  torch.Size([4, 512, 4, 4])\n",
      "Reconstructed Image's Shape:  torch.Size([4, 3, 256, 256])\n",
      "Segmentation Mask's Shape:  torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class Image2Image2Mask(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Image2Image2Mask, self).__init__()\n",
    "\n",
    "        self.image2imageAE = AutoEncoder()\n",
    "        self.unet = UNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        imageLatent, reconsImage = self.image2imageAE(x)\n",
    "        segMask = self.unet(reconsImage)\n",
    "        return imageLatent, reconsImage, segMask\n",
    "\n",
    "\n",
    "print(\"Combined Model\")\n",
    "data = (torch.rand(size=(4, 3, 256, 256)))\n",
    "i2i2m = Image2Image2Mask()\n",
    "imageLatent, reconsImage, segMask = i2i2m(data)\n",
    "print(\"Latent's Shape: \", imageLatent.shape)\n",
    "print(\"Reconstructed Image's Shape: \", reconsImage.shape)\n",
    "print(\"Segmentation Mask's Shape: \", segMask.shape)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Datasets/BDD 100K\\\\images/100k\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 53\u001b[0m\n\u001b[0;32m     49\u001b[0m         val_loader \u001b[39m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m train_loader, val_loader, test_loader\n\u001b[1;32m---> 53\u001b[0m train_data, val_data, test_data \u001b[39m=\u001b[39m DataSet(BATCH_SIZE)\u001b[39m.\u001b[39;49mget_data()\n\u001b[0;32m     54\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_data))\n\u001b[0;32m     55\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(val_data))\n",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m, in \u001b[0;36mDataSet.get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 43\u001b[0m     train_dataset \u001b[39m=\u001b[39m AutoencoderDataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_dir, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, transform\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform)\n\u001b[0;32m     44\u001b[0m     test_dataset \u001b[39m=\u001b[39m AutoencoderDataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, transform\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform)\n\u001b[0;32m     45\u001b[0m     val_dataset \u001b[39m=\u001b[39m AutoencoderDataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m, transform\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform)\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mAutoencoderDataset.__init__\u001b[1;34m(self, root_dir, subset, transform)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root_dir, \u001b[39m'\u001b[39m\u001b[39mimages/100k\u001b[39m\u001b[39m'\u001b[39m, subset)\n\u001b[0;32m      8\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_paths \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_dir):\n\u001b[0;32m     10\u001b[0m     folder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_dir, folder)\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(folder_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Datasets/BDD 100K\\\\images/100k\\\\train'"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.data.iloc[index, 0]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        # Preprocess the image if needed\n",
    "        # ...\n",
    "\n",
    "        # Convert image to tensor\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            # Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        image_tensor = transform(image)\n",
    "\n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_data(self):\n",
    "        train_csv = \"Datasets/BDD 100K/images/train.csv\"\n",
    "        val_csv = \"Datasets/BDD 100K/images/val.csv\"\n",
    "        test_csv = \"Datasets/BDD 100K/images/test.csv\"\n",
    "\n",
    "        train_dataset = CustomDataset(train_csv)\n",
    "        val_dataset = CustomDataset(val_csv)\n",
    "        test_dataset = CustomDataset(test_csv)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 1.0\n",
    "        self.classes = 3\n",
    "        self.ignore_index = None\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + self.smooth\n",
    "        )\n",
    "        return 1. - dsc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class JaccardScore(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(JaccardScore, self).__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = torch.logical_and(y_true, y_pred)\n",
    "        union = torch.logical_or(y_true, y_pred)\n",
    "        iou_score = torch.sum(intersection) / torch.sum(union)  \n",
    "        return iou_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MixedLoss(nn.Module):\n",
    "  def __init__(self, alpha, beta):\n",
    "    super(MixedLoss, self).__init__()\n",
    "    self.alpha = alpha\n",
    "    self.beta = beta\n",
    "\n",
    "  def forward(self, y_pred, y_true):\n",
    "    # y_pred and y_true are of shape (batch_size, channels, height, width)\n",
    "    # compute the MS-SSIM loss\n",
    "    msssim_loss = 1 - ms_ssim(y_pred, y_true)\n",
    "    # compute the L2 loss\n",
    "    l2_loss = nn.MSELoss()(y_pred, y_true)\n",
    "    # return the mixed loss\n",
    "    return self.alpha*msssim_loss + self.beta*l2_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Model class to train, test, validate and infer the Image-to-Image Autoencoder Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    " \n",
    "    def __init__(self, trained=False):\n",
    "        self.model = AutoEncoder().to(DEVICE)\n",
    "        self.jaccard = JaccardScore()\n",
    "\n",
    "    def psnr(self, reconstructed, original, max_val=1.0): return 20 * torch.log10(max_val / torch.sqrt(F.mse_loss(reconstructed, original)))        \n",
    "\n",
    "\n",
    "    def train(self, dataset, loss_func, optimizer):\n",
    "\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "        counter = 0\n",
    "        \n",
    "        for i, img in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "            counter += 1\n",
    "            image= img.to(DEVICE)\n",
    "\n",
    "            noise_image = image + torch.randn(image.size()).to(DEVICE) * 0.05 + 0.0\n",
    "            \n",
    "            output = self.model(noise_image)\n",
    "            loss = loss_func(output[1], image)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #calculate the Jaccard score here\n",
    "            psnr = self.psnr(output[1], image)\n",
    "            running_psnr += psnr.item()\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / (counter*BATCH_SIZE)\n",
    "        epoch_psnr = running_psnr / counter\n",
    "\n",
    "        return epoch_loss, epoch_psnr\n",
    "\n",
    "\n",
    "\n",
    "    def validate(self, dataset):\n",
    "\n",
    "        self.model.eval()\n",
    "        running_correct = 0.0\n",
    "        running_psnr = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, img in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "                counter += 1\n",
    "                img = img.to(DEVICE)\n",
    "                output = self.model(img)\n",
    "\n",
    "                psnr = self.psnr(output[1], img)\n",
    "                running_psnr += psnr.item()\n",
    "    \n",
    "        epoch_psnr = running_psnr / counter\n",
    "        return epoch_psnr\n",
    "\n",
    "\n",
    "\n",
    "    def test(self, dataset, epoch):\n",
    "        running_psnr = 0.0  \n",
    "        counter = 0\n",
    "        num = random.randint(0, len(dataset) // (BATCH_SIZE // 2))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, img in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "                counter += 1\n",
    "                img = img.to(DEVICE)\n",
    "                output = self.model(img)\n",
    "                pred = output[1]\n",
    "                psnr = self.psnr(output[1], img)  \n",
    "                running_psnr += psnr.item()\n",
    "\n",
    "                if i == num:\n",
    "                    try:\n",
    "                        os.makedirs(f\"saved_samples/{MODEL_NAME}\", exist_ok=True)\n",
    "                    except:\n",
    "                        pass\n",
    "                    image = img[0, :, :, :].cpu().numpy().transpose((1, 2, 0))\n",
    "                    pred = pred[0, :, :, :].cpu().numpy().transpose((1, 2, 0))\n",
    "                    image = (image * 255).astype('uint8')\n",
    "                    pred = (pred * 255).astype('uint8')\n",
    "                    image_pil = Image.fromarray(image)  \n",
    "                    pred_pil = Image.fromarray(pred)  \n",
    "                    stacked_image = Image.new('RGB', (image_pil.width * 2, image_pil.height))\n",
    "                    stacked_image.paste(image_pil, (0, 0))\n",
    "                    stacked_image.paste(pred_pil, (image_pil.width, 0))\n",
    "\n",
    "                    stacked_image.save(f\"saved_samples/{MODEL_NAME}/{epoch}.jpg\")\n",
    "\n",
    "        epoch_psnr = running_psnr / counter \n",
    "        return epoch_psnr\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    def fit(self, epochs, lr):\n",
    "\n",
    "        print(f\"Using {DEVICE} device...\")\n",
    "        print(\"Loading Datasets...\")\n",
    "        train_data, val_data, test_data = CustomDataLoader(BATCH_SIZE).get_data()\n",
    "        print(\"Dataset Loaded.\")\n",
    "\n",
    "        print(\"Initializing Parameters...\")\n",
    "        self.model = self.model.to(DEVICE)\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        print(f\"The total parameters of the model are: {total_params}\")\n",
    "\n",
    "        print(f\"Initializing the Optimizer\")\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr)\n",
    "        print(f\"Beginning to train...\")\n",
    "\n",
    "        diceloss = DiceLoss()\n",
    "\n",
    "        val_psnr_epochs = []\n",
    "        writer = SummaryWriter(f'runs/{MODEL_NAME}/')\n",
    "        os.makedirs(\"checkpoints/\", exist_ok=True)\n",
    "        os.makedirs(\"saved_model/\", exist_ok=True)\n",
    "\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            print(f\"Epoch No: {epoch}\")\n",
    "\n",
    "            train_loss, train_psnr = self.train(dataset=train_data, loss_func=diceloss, optimizer=optimizer)\n",
    "\n",
    "            val_psnr = self.validate(dataset=val_data)\n",
    "            val_psnr_epochs.append(val_psnr)\n",
    "\n",
    "            print(f\"Train Loss:{train_loss}, Train Jaccard Score:{train_psnr}, Validation Jaccard Score:{val_psnr}\")\n",
    "\n",
    "            writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "            writer.add_scalar(\"PSNR/Train\", train_psnr, epoch)\n",
    "            writer.add_scalar(\"PSNR/Val\", val_psnr, epoch)\n",
    "\n",
    "\n",
    "            if max(val_psnr_epochs) == val_psnr:\n",
    "                torch.save(self.model.state_dict(), f\"checkpoints/{MODEL_NAME}.pth\")\n",
    "            \n",
    "            if epoch%5==0:\n",
    "                print(\"Saving model\")\n",
    "                torch.save(self.model.state_dict(), f\"saved_model/{MODEL_NAME}_{epoch}.pth\")\n",
    "                test_psnr = self.test(test_data, epoch)\n",
    "                writer.add_scalar(\"PSNR/Test\", test_psnr)\n",
    "                print(\"Model Saved\")\n",
    "\n",
    "    \n",
    "            print(\"Epoch Completed. Proceeding to next epoch...\")\n",
    "\n",
    "        print(f\"Training Completed for {epochs} epochs.\")\n",
    "\n",
    "\n",
    "    def infer_a_random_sample(self):\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(f\"test_samples/{MODEL_NAME}\", exist_ok=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model()\n",
    "model.fit(250, 5e-5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
